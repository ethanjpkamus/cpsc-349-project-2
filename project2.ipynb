{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da18f709",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "## Members\n",
    "* Ethan Kamus\n",
    "* Nathaniel Marquez\n",
    "* Rebecca Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765fb3e",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a8b71ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('dataset.csv',delimiter=',',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf4e92",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1b23f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = data[0:900]\n",
    "test_set = data[900:1000]\n",
    "\n",
    "len(training_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2465e1c",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "47ef60c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69333661, 0.03664626, 0.02839225])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert training set to 2D array and \n",
    "training_set = np.array(training_set)\n",
    "# create x1 and x2 vectors\n",
    "x1 = training_set[0:900,[0]]\n",
    "x2 = training_set[0:900,[1]]\n",
    "# create feature vector with ones column and x1, x2 attributes\n",
    "X = np.hstack((np.ones_like(x1),x1,x2))\n",
    "# target column vector\n",
    "t = training_set[0:900,[2]] # matrix of output?\n",
    "t = t.reshape(900,)\n",
    "\n",
    "# differentiate with respect to w to get following optimal weight values\n",
    "XX = np.dot(X.T,X)\n",
    "inverse_XX = np.linalg.inv(XX)\n",
    "Xt = np.dot(X.T,t)\n",
    "w = np.dot(inverse_XX,Xt)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db7b81",
   "metadata": {},
   "source": [
    "$$ y = 0.65683428 - 0.00632862x_1 - 0.00483534x_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a9b26",
   "metadata": {},
   "source": [
    "# Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "81403d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.599408015247962"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_0 = w[0]\n",
    "w_1 = w[1]\n",
    "w_2 = w[2]\n",
    "# X = arr[0:900,[1,2]]\n",
    "predictions = []\n",
    "for i in X:\n",
    "    predictions = np.append(predictions, [[w_0 + (i[0]*w_1) + (i[1]*w_2)]])\n",
    "#     predictions.append(np.array([w_0 + (i[0]*w_1) + (i[1]*w_2)]))\n",
    "loss = t - predictions\n",
    "loss = np.square(loss)\n",
    "avg_sq_loss = np.sum(loss)/len(loss)\n",
    "avg_sq_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3469e4",
   "metadata": {},
   "source": [
    "MSE: 0.1903883621895976"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5eb55",
   "metadata": {},
   "source": [
    "# Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ba7de446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.587120688069552"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = np.hstack((np.ones_like(x1),x1,x2))\n",
    "X = np.hstack((np.ones_like(x1),x1,x2, np.square(x1), np.square(x2)))\n",
    "XX = np.dot(X.T,X)\n",
    "inverse_XX = np.linalg.inv(XX)\n",
    "Xt = np.dot(X.T,t)\n",
    "wq = np.dot(inverse_XX,Xt)\n",
    "\n",
    "wq_0 = wq[0]\n",
    "wq_1 = wq[1]\n",
    "wq_2 = wq[2]\n",
    "wq_12 = wq[3]\n",
    "wq_22 = wq[4]\n",
    "\n",
    "predictions = []\n",
    "for i in X:\n",
    "    predictions = np.append(predictions, [[wq_0 + (i[1]*wq_1) \n",
    "                                     + (i[2]*wq_2) \n",
    "                                     + ((i[3])*wq_12) \n",
    "                                     + ((i[4])*wq_22)]])\n",
    "loss = t - predictions\n",
    "loss = np.square(loss)\n",
    "avg_sq_loss = np.sum(loss)/len(loss)\n",
    "avg_sq_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b1965",
   "metadata": {},
   "source": [
    "$$ y = 0.31183988 - 0.00377483x_1 + 0.00781421x_2 + 0.17753899x_1^2 + 0.08813606x_2^2 $$\n",
    "\n",
    "MSE: 0.1544028141884278"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3087f69",
   "metadata": {},
   "source": [
    "# Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c84cadaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.884912072267476, 7.882170673013778)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = np.array(test_set)\n",
    "x1 = test_set[0:,[0]] # matrix of features?\n",
    "x2 = test_set[0:,[1]]\n",
    "t = test_set[0:,[2]]\n",
    "t = t.reshape(100,)\n",
    "\n",
    "X = np.hstack((np.ones_like(x1),x1,x2))\n",
    "\n",
    "# linear\n",
    "lin_predictions = []\n",
    "for i in X:\n",
    "    lin_predictions = np.append(lin_predictions, [[w_0 + (i[0]*w_1) + (i[1]*w_2)]])\n",
    "loss = t - lin_predictions\n",
    "loss = np.square(loss)\n",
    "test_mse = np.sum(loss)/len(loss)\n",
    "\n",
    "# quadratic\n",
    "X = np.hstack((X, np.square(x1), np.square(x2)))\n",
    "quad_predictions = []\n",
    "for i in X:\n",
    "    quad_predictions = np.append(quad_predictions, [[wq_0 + (i[1]*wq_1) \n",
    "                                     + (i[2]*wq_2) \n",
    "                                     + ((i[3])*wq_12) \n",
    "                                     + ((i[4])*wq_22)]])\n",
    "loss = t - quad_predictions\n",
    "loss = np.square(loss)\n",
    "test_mse_q = np.sum(loss)/len(loss)\n",
    "test_mse, test_mse_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e991f8",
   "metadata": {},
   "source": [
    "# Experiment 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e6e396d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(weights, X_vector, t_vector):\n",
    "    predictions = []\n",
    "    for i in X_vector:\n",
    "        temp = 0\n",
    "        for j in range(int(len(weights))):\n",
    "            temp = temp + (i[j] * weights[j])\n",
    "#             print(f'ij ----- {i[j]} * wj ----- {weights[j]} ---- temp {temp}\\n\\n')\n",
    "        predictions = np.append(predictions, temp)\n",
    "    loss = t_vector - predictions\n",
    "    loss = np.square(loss)\n",
    "    mse = np.sum(loss)/len(loss)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "938ffc3b-ee1d-4459-bff9-c36640ea97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(order, x1, x2, target_set, isValidation = False):\n",
    "    X_order = np.ones_like(x1)\n",
    "    for x in range(1, order+1):\n",
    "        X_order = np.hstack((X_order, np.power(x1, x), np.power(x2,x)))\n",
    "    \n",
    "    if (isValidation):\n",
    "        return X_order\n",
    "\n",
    "    XX_order = np.dot(X_order.T,X_order)\n",
    "    inverse_XX_order = np.linalg.inv(XX_order)\n",
    "    Xt_order = np.dot(X_order.T,target_set)\n",
    "    w_order = (np.dot(inverse_XX_order,Xt_order))\n",
    "    \n",
    "    \n",
    "    return w_order, X_order # return as a tuple in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6de74fe6-2373-46ce-9dda-30b7af961fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = []\n",
    "validation_loss = []\n",
    "def cross_validation(order, training_data):\n",
    "    k = 5\n",
    "    fold = int(len(training_data) / k)\n",
    "    \n",
    "    for i in range(1, order+1):\n",
    "        j = 0\n",
    "        test_mse, cv_mse = 0, 0\n",
    "        for f in range(1, k+1):\n",
    "            validation = np.array(training_data[int(j*fold):int(f*fold)])\n",
    "            training = np.delete(training_data, slice(int(j*fold),int(f*fold)), 0)\n",
    "            valid_x1, valid_x2, valid_t = validation[0:,[0]], validation[0:,[1]], validation[0:,[2]]\n",
    "            valid_t = valid_t.reshape(valid_t.size)\n",
    "            \n",
    "            training_x1, training_x2, training_t = training[0:,[0]], training[0:,[1]], training[0:,[2]]\n",
    "            training_t = training_t.reshape(training_t.size)\n",
    "            \n",
    "            t_results = calculate_weights(i, training_x1, training_x2, training_t)\n",
    "            weights = t_results[0]\n",
    "            tX_order = t_results[1]\n",
    "#             training_loss.append(calculate_loss(weights, tX_order, training_t))\n",
    "\n",
    "            vX_order = calculate_weights(i, valid_x1, valid_x2, valid_t, isValidation = True)\n",
    "#             validation_loss.append(calculate_loss(weights, vX_order, valid_t))\n",
    "            \n",
    "            test_mse += calculate_loss(weights, tX_order, training_t)\n",
    "            cv_mse += calculate_loss(weights, vX_order, valid_t)\n",
    "            j += 1\n",
    "        training_loss.append(test_mse / k)\n",
    "        validation_loss.append(cv_mse / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b2b95939-75c9-4ec0-9bec-31dcc8f69d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Training Loss Results: ',\n",
       " [8.585424175136499,\n",
       "  8.570015371698974,\n",
       "  8.562578349639221,\n",
       "  8.534275710525652,\n",
       "  8.42451734640557,\n",
       "  8.402263856675853,\n",
       "  8.38645590352802,\n",
       "  8.37100125996366],\n",
       " 'Validation Loss Results: ',\n",
       " [8.664561780661654,\n",
       "  8.744172714794733,\n",
       "  8.810585695415508,\n",
       "  8.93906138050797,\n",
       "  9.17732387419126,\n",
       "  8.833396216294403,\n",
       "  8.888724100285973,\n",
       "  9.65476890762137])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(8, training_set)\n",
    "'Training Loss Results: ', training_loss , 'Validation Loss Results: ', validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525953bd-b5a4-4689-8971-e4c9e5a12340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
